{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d80ad095",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MAR experiments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation (Run once to get the dataset csv file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/Concrete_Data.xls\"\n",
    ")\n",
    "last_col = data.columns[-1]\n",
    "data.drop(columns=[last_col], inplace=True)\n",
    "# rename\n",
    "data.rename({\n",
    "    c: 'Z_{}'.format(i) for c, i in zip(data.columns, range(len(data.columns)))\n",
    "}, axis=1, inplace=True)\n",
    "\n",
    "# normalize\n",
    "for c in data.columns:\n",
    "    data[c] = (data[c] - data[c].min()) / (data[c].max() - data[c].min())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data.to_csv('normalized_data.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "gdf = '# nodes\\n'\n",
    "for c in data.columns:\n",
    "    gdf += '{}: data(./normalized_data.csv)\\n'.format(c)\n",
    "with open('gdf_Z.yml', 'w') as file:\n",
    "    file.write(gdf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Main"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run the same scenario as the original paper\n",
    "\n",
    "Run the script `mar_original_paper_experiment.py`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradually increasing Z->R edges' density"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRAPH_DENSITY: 0.0, EPOCH: 0\n"
     ]
    },
    {
     "ename": "ConstructorError",
     "evalue": "could not determine a constructor for the tag 'tag:yaml.org,2002:python/object/apply:numpy.core.multiarray.scalar'\n  in \"./temp_analysis_guideline.yml\", line 4, column 18",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mConstructorError\u001B[0m                          Traceback (most recent call last)",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     37\u001B[0m mask \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(np\u001B[38;5;241m.\u001B[39mzeros(shape\u001B[38;5;241m=\u001B[39m(N_total, N_m)), index\u001B[38;5;241m=\u001B[39mtotal_v,\n\u001B[1;32m     38\u001B[0m                     columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mR_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(i\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m miss_v])\n\u001B[1;32m     39\u001B[0m mask\u001B[38;5;241m.\u001B[39mloc[obs_v, :] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m---> 40\u001B[0m rndz \u001B[38;5;241m=\u001B[39m \u001B[43mConnectRandomizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparent_graph_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgdf_Z.yml\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchild_graph_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgdf_R.yml\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mguideline_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdir_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[43m                         \u001B[49m\u001B[43madj_matrix_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;66;03m# 5. samples\u001B[39;00m\n\u001B[1;32m     43\u001B[0m nodes, edges \u001B[38;5;241m=\u001B[39m rndz\u001B[38;5;241m.\u001B[39mget_graph_params()\n",
      "File \u001B[0;32m~/Desktop/projects/simulator/parcs/graph_builder/randomizer.py:241\u001B[0m, in \u001B[0;36mConnectRandomizer.__init__\u001B[0;34m(self, parent_graph_dir, child_graph_dir, guideline_dir, adj_matrix_mask, delete_temp_graph_description)\u001B[0m\n\u001B[1;32m    238\u001B[0m e_c \u001B[38;5;241m=\u001B[39m [n \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m cgd \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m->\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m n]\n\u001B[1;32m    239\u001B[0m l_c \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(n_c)\n\u001B[0;32m--> 241\u001B[0m guideline \u001B[38;5;241m=\u001B[39m \u001B[43mconfig_parser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mguideline_dir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[38;5;66;03m# sample connection adj_matrix\u001B[39;00m\n\u001B[1;32m    244\u001B[0m density \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdirective_picker(guideline[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgraph\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgraph_density\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[0;32m~/Desktop/projects/simulator/parcs/graph_builder/utils.py:8\u001B[0m, in \u001B[0;36mconfig_parser\u001B[0;34m(dir_)\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconfig_parser\u001B[39m(dir_):\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(dir_, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m stream:\n\u001B[0;32m----> 8\u001B[0m         conf \u001B[38;5;241m=\u001B[39m \u001B[43myaml\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msafe_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m conf\n",
      "File \u001B[0;32m~/Desktop/projects/simulator/venv/lib/python3.8/site-packages/yaml/__init__.py:125\u001B[0m, in \u001B[0;36msafe_load\u001B[0;34m(stream)\u001B[0m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msafe_load\u001B[39m(stream):\n\u001B[1;32m    118\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;124;03m    Parse the first YAML document in a stream\u001B[39;00m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;124;03m    and produce the corresponding Python object.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;124;03m    to be safe for untrusted input.\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mSafeLoader\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/projects/simulator/venv/lib/python3.8/site-packages/yaml/__init__.py:81\u001B[0m, in \u001B[0;36mload\u001B[0;34m(stream, Loader)\u001B[0m\n\u001B[1;32m     79\u001B[0m loader \u001B[38;5;241m=\u001B[39m Loader(stream)\n\u001B[1;32m     80\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 81\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mloader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_single_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     83\u001B[0m     loader\u001B[38;5;241m.\u001B[39mdispose()\n",
      "File \u001B[0;32m~/Desktop/projects/simulator/venv/lib/python3.8/site-packages/yaml/constructor.py:51\u001B[0m, in \u001B[0;36mBaseConstructor.get_single_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     49\u001B[0m node \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_single_node()\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m node \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstruct_document\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/projects/simulator/venv/lib/python3.8/site-packages/yaml/constructor.py:60\u001B[0m, in \u001B[0;36mBaseConstructor.construct_document\u001B[0;34m(self, node)\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate_generators \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     59\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m generator \u001B[38;5;129;01min\u001B[39;00m state_generators:\n\u001B[0;32m---> 60\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m dummy \u001B[38;5;129;01min\u001B[39;00m generator:\n\u001B[1;32m     61\u001B[0m             \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconstructed_objects \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[0;32m~/Desktop/projects/simulator/venv/lib/python3.8/site-packages/yaml/constructor.py:413\u001B[0m, in \u001B[0;36mSafeConstructor.construct_yaml_map\u001B[0;34m(self, node)\u001B[0m\n\u001B[1;32m    411\u001B[0m data \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    412\u001B[0m \u001B[38;5;28;01myield\u001B[39;00m data\n\u001B[0;32m--> 413\u001B[0m value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstruct_mapping\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    414\u001B[0m data\u001B[38;5;241m.\u001B[39mupdate(value)\n",
      "File \u001B[0;32m~/Desktop/projects/simulator/venv/lib/python3.8/site-packages/yaml/constructor.py:218\u001B[0m, in \u001B[0;36mSafeConstructor.construct_mapping\u001B[0;34m(self, node, deep)\u001B[0m\n\u001B[1;32m    216\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(node, MappingNode):\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mflatten_mapping(node)\n\u001B[0;32m--> 218\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstruct_mapping\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdeep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdeep\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/projects/simulator/venv/lib/python3.8/site-packages/yaml/constructor.py:143\u001B[0m, in \u001B[0;36mBaseConstructor.construct_mapping\u001B[0;34m(self, node, deep)\u001B[0m\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, collections\u001B[38;5;241m.\u001B[39mabc\u001B[38;5;241m.\u001B[39mHashable):\n\u001B[1;32m    141\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ConstructorError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwhile constructing a mapping\u001B[39m\u001B[38;5;124m\"\u001B[39m, node\u001B[38;5;241m.\u001B[39mstart_mark,\n\u001B[1;32m    142\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound unhashable key\u001B[39m\u001B[38;5;124m\"\u001B[39m, key_node\u001B[38;5;241m.\u001B[39mstart_mark)\n\u001B[0;32m--> 143\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstruct_object\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue_node\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdeep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdeep\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    144\u001B[0m     mapping[key] \u001B[38;5;241m=\u001B[39m value\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m mapping\n",
      "File \u001B[0;32m~/Desktop/projects/simulator/venv/lib/python3.8/site-packages/yaml/constructor.py:100\u001B[0m, in \u001B[0;36mBaseConstructor.construct_object\u001B[0;34m(self, node, deep)\u001B[0m\n\u001B[1;32m     98\u001B[0m             constructor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39mconstruct_mapping\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tag_suffix \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 100\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mconstructor\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    102\u001B[0m     data \u001B[38;5;241m=\u001B[39m constructor(\u001B[38;5;28mself\u001B[39m, tag_suffix, node)\n",
      "File \u001B[0;32m~/Desktop/projects/simulator/venv/lib/python3.8/site-packages/yaml/constructor.py:427\u001B[0m, in \u001B[0;36mSafeConstructor.construct_undefined\u001B[0;34m(self, node)\u001B[0m\n\u001B[1;32m    426\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconstruct_undefined\u001B[39m(\u001B[38;5;28mself\u001B[39m, node):\n\u001B[0;32m--> 427\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ConstructorError(\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    428\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcould not determine a constructor for the tag \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m node\u001B[38;5;241m.\u001B[39mtag,\n\u001B[1;32m    429\u001B[0m             node\u001B[38;5;241m.\u001B[39mstart_mark)\n",
      "\u001B[0;31mConstructorError\u001B[0m: could not determine a constructor for the tag 'tag:yaml.org,2002:python/object/apply:numpy.core.multiarray.scalar'\n  in \"./temp_analysis_guideline.yml\", line 4, column 18"
     ]
    }
   ],
   "source": [
    "from parcs.helpers.missing_data import R_adj_matrix, indicator_graph_description_file, m_graph_convert\n",
    "from parcs.graph_builder.randomizer import ConnectRandomizer, guideline_iterator\n",
    "from parcs.cdag.graph_objects import Graph\n",
    "import random as rand\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "from hyperimpute.utils.distributions import enable_reproducible_results\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 0. configs\n",
    "data = pd.read_csv('normalized_data.csv')\n",
    "N = 700  # number of samples\n",
    "N_total = len(data.columns) # number of total variables\n",
    "N_O = 4  # number of fully observed variables\n",
    "N_m = N_total - N_O  # number of missing feauters\n",
    "miss_ratio = 0.5  # missing ratio in total\n",
    "\n",
    "results = {}\n",
    "for dir_, epoch, value in guideline_iterator(guideline_dir='guideline_2.yml',\n",
    "                                             to_iterate='graph/graph_density',\n",
    "                                             steps=5, repeat=10):\n",
    "    print('GRAPH_DENSITY: {}, EPOCH: {}'.format(value, epoch))\n",
    "    results[value] = {'hyperimpute': [], 'missforest': []}\n",
    "    enable_reproducible_results(epoch)\n",
    "    # 2. fully and partially observed variables\n",
    "    obs_v = sorted(rand.sample(['Z_{}'.format(i) for i in range(N_total)], N_O))\n",
    "    miss_v = sorted(list(set(data.columns) - set(obs_v)))\n",
    "    total_v = sorted(obs_v + miss_v)\n",
    "    # 3. write GDF for R\n",
    "    indicator_graph_description_file(adj_matrix=np.zeros(shape=(N_m, N_m)),\n",
    "                                     node_names=miss_v, miss_ratio=miss_ratio, subscript_only=True,\n",
    "                                     file_dir='./gdf_R.yml')\n",
    "    # 4. randomize\n",
    "    mask = pd.DataFrame(np.zeros(shape=(N_total, N_m)), index=total_v,\n",
    "                        columns=['R_{}'.format(i.split('_')[1]) for i in miss_v])\n",
    "    mask.loc[obs_v, :] = 1\n",
    "    rndz = ConnectRandomizer(parent_graph_dir='gdf_Z.yml', child_graph_dir='gdf_R.yml', guideline_dir=dir_,\n",
    "                             adj_matrix_mask=mask)\n",
    "    # 5. samples\n",
    "    nodes, edges = rndz.get_graph_params()\n",
    "    g = Graph(nodes=nodes, edges=edges)\n",
    "    s = g.sample(N)\n",
    "    # outputs\n",
    "    gt = s[total_v]\n",
    "    ds = m_graph_convert(s, missingness_prefix='R_', shared_subscript=True)\n",
    "\n",
    "    # main thread\n",
    "    mask = ds.isna().values\n",
    "    mf = Imputers().get('missforest')\n",
    "    hi = Imputers().get('hyperimpute')\n",
    "    imp_hi = hi.fit_transform(ds)\n",
    "    imp_mf = mf.fit_transform(ds)\n",
    "    results[value]['hyperimpute'].append(RMSE(gt.values, imp_hi.values, mask))\n",
    "    results[value]['missforest'].append(RMSE(gt.values, imp_mf.values, mask))\n",
    "    del gt, ds, mask, mf, hi, imp_hi, imp_mf\n",
    "\n",
    "with open('MAR_ZR_edge_density_variation.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from parcs.helpers.missing_data import R_adj_matrix, indicator_graph_description_file, m_graph_convert\n",
    "from parcs.graph_builder.randomizer import ConnectRandomizer\n",
    "from parcs.cdag.graph_objects import Graph\n",
    "import random as rand\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 0. configs\n",
    "data = pd.read_csv('normalized_data.csv')\n",
    "N = 700  # number of samples\n",
    "N_total = len(data.columns) # number of total variables\n",
    "N_O = 4  # number of fully observed variables\n",
    "miss_ratio = 0.5  # missing ratio in total\n",
    "\n",
    "def get_miss_dataset(density_R=None):\n",
    "    # 2. fully and partially observed variables\n",
    "    obs_v = rand.sample(['Z_{}'.format(i) for i in range(N_total)], N_O)\n",
    "    miss_v = list(set(data.columns) - set(obs_v))\n",
    "    total_v = sorted(obs_v + miss_v)\n",
    "    # 3. write GDF for R\n",
    "    r_mask = R_adj_matrix(size=N_total-N_O, density=density_R)\n",
    "    indicator_graph_description_file(\n",
    "        adj_matrix=r_mask,\n",
    "        node_names=miss_v,\n",
    "        prefix='R',\n",
    "        miss_ratio=miss_ratio,\n",
    "        supress_asteriks=False,\n",
    "        subscript_only=True,\n",
    "        file_dir='./gdf_R.yml'\n",
    "    )\n",
    "    # 4. randomize\n",
    "    rndz = ConnectRandomizer(\n",
    "    parent_graph_dir='gdf_Z.yml',\n",
    "    child_graph_dir='gdf_R.yml',\n",
    "    guideline_dir='guideline_1.yml',\n",
    "    adj_matrix_mask=pd.DataFrame(np.ones(shape=(N_total, N_total-N_O)),\n",
    "                                 index=data.columns,\n",
    "                                 columns=['R_{}'.format(i.split('_')[1]) for i in miss_v])\n",
    "    )\n",
    "    # 5. samples\n",
    "    nodes, edges = rndz.get_graph_params()\n",
    "    g = Graph(nodes=nodes, edges=edges)\n",
    "    s = g.sample(N)\n",
    "\n",
    "    # outputs\n",
    "    gt = s[total_v]\n",
    "    ds = m_graph_convert(s, missingness_prefix='R_', shared_subscript=True)\n",
    "    return gt, ds[total_v]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## linear vs. nonlinear"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# linear\n",
    "np.random.seed(2022)\n",
    "rmse_hi = []\n",
    "rmse_mf = []\n",
    "for it in range(iters):\n",
    "    print(it)\n",
    "    gt, ds = get_miss_dataset(density_R=0, linear=True)\n",
    "    mask = ds.isna().values\n",
    "    mf = Imputers().get('missforest')\n",
    "    hi = Imputers().get('hyperimpute')\n",
    "    imp_hi = hi.fit_transform(ds)\n",
    "    imp_mf = mf.fit_transform(ds)\n",
    "    rmse_hi.append(RMSE(gt.values, imp_hi.values, mask))\n",
    "    rmse_mf.append(RMSE(gt.values, imp_mf.values, mask))\n",
    "\n",
    "results = {'hyperimpute': rmse_hi, 'missforest': rmse_mf}\n",
    "\n",
    "with open('MAR_linear_uci.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(2022)\n",
    "# nonlinear\n",
    "rmse_hi = []\n",
    "rmse_mf = []\n",
    "for it in range(iters):\n",
    "    print(it)\n",
    "    gt, ds = get_miss_dataset(density_R=0, linear=False)\n",
    "    mask = ds.isna().values\n",
    "    mf = Imputers().get('missforest')\n",
    "    hi = Imputers().get('hyperimpute')\n",
    "    imp_hi = hi.fit_transform(ds)\n",
    "    imp_mf = mf.fit_transform(ds)\n",
    "    rmse_hi.append(RMSE(gt.values, imp_hi.values, mask))\n",
    "    rmse_mf.append(RMSE(gt.values, imp_mf.values, mask))\n",
    "\n",
    "results = {'hyperimpute': rmse_hi, 'missforest': rmse_mf}\n",
    "\n",
    "with open('MAR_nonlinear_uci.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "\n",
    "with open('MAR_linear_uci.json') as f:\n",
    "    res_l = json.load(f)\n",
    "\n",
    "with open('MAR_nonlinear_uci.json') as f:\n",
    "    res_nl = json.load(f)\n",
    "\n",
    "print(np.mean(res_l['hyperimpute']), np.std(res_l['hyperimpute']))\n",
    "print(np.mean(res_l['missforest']), np.std(res_l['missforest']))\n",
    "\n",
    "print(np.mean(res_nl['hyperimpute']), np.std(res_nl['hyperimpute']))\n",
    "print(np.mean(res_nl['missforest']), np.std(res_nl['missforest']))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "\n",
    "range_ = np.linspace(0, 1, 3)\n",
    "\n",
    "rmse_mean = []\n",
    "rmse_std = []\n",
    "for r_density in range_:\n",
    "    print(r_density)\n",
    "    temp = []\n",
    "    for it in range(3):\n",
    "        gt, ds = get_miss_dataset(density_R=r_density)\n",
    "        mask = ds.isna().values\n",
    "        n = mask.sum()\n",
    "        # hpi = SimpleImputer(strategy='mean')\n",
    "        hpi = Imputers().get(\n",
    "            'hyperimpute',\n",
    "            optimizer='hyperband',\n",
    "            classifier_seed=['random_forest'],\n",
    "            regression_seed=['random_forest_regressor']\n",
    "        )\n",
    "        imp = hpi.fit_transform(ds)\n",
    "        temp.append(\n",
    "            np.sqrt(\n",
    "                np.sum(\n",
    "                    np.square(gt.values[mask] - imp.values[mask])\n",
    "                )/n\n",
    "            )\n",
    "        )\n",
    "    rmse_mean.append(np.mean(temp))\n",
    "    rmse_std.append(np.std(temp))\n",
    "\n",
    "plt.errorbar(range_, rmse_mean, rmse_std, marker='^')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from matplotlib import pyplot as plt\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "\n",
    "range_ = np.linspace(0, 1, 2)\n",
    "rmse_mean = []\n",
    "rmse_std = []\n",
    "for r_density in range_:\n",
    "    print(r_density)\n",
    "    temp = []\n",
    "    for it in range(10):\n",
    "        gt, ds = get_miss_dataset(density_R=r_density)\n",
    "        # kni = KNNImputer(n_neighbors=5)\n",
    "        hpi = Imputers().get(\n",
    "            'hyperimpute',\n",
    "            optimizer='hyperband',\n",
    "            classifier_seed=['logistic_regression'],\n",
    "            regression_seed=['linear_regression']\n",
    "        )\n",
    "        imp = hpi.fit_transform(ds)\n",
    "        temp.append(np.sqrt(np.sum(np.square(gt.values - imp.values))/N))\n",
    "    rmse_mean.append(np.mean(temp))\n",
    "    rmse_std.append(np.std(temp))\n",
    "\n",
    "plt.errorbar(range_, rmse_mean, rmse_std, marker='^')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
